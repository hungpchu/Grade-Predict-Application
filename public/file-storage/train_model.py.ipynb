{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = \n",
      "\n",
      "             Assignment 1  Lab 1       Lab 2       Lab 3\n",
      "days online                                             \n",
      "0               92.000000    100    0.000000  100.000000\n",
      "1               87.000000      0  100.000000  100.000000\n",
      "7              100.000000    100  100.000000   99.500000\n",
      "0               95.000000    100  100.000000  100.000000\n",
      "19               9.000000    100  100.000000  100.000000\n",
      "13             100.000000    100  100.000000  100.000000\n",
      "4              100.000000    100  100.000000  100.000000\n",
      "3               98.000000    100  100.000000  100.000000\n",
      "12              34.000000    100  100.000000   99.500000\n",
      "0               29.000000    100  100.000000  100.000000\n",
      "15             100.000000    100  100.000000  100.000000\n",
      "14             100.000000    100  100.000000  100.000000\n",
      "10              15.000000    100  100.000000  100.000000\n",
      "0                0.000000    100   50.000000  100.000000\n",
      "4              100.000000    100  100.000000  100.000000\n",
      "0               95.000000    100  100.000000  100.000000\n",
      "0               97.000000     97  100.000000   99.000000\n",
      "0               61.000000    100   99.500000  100.000000\n",
      "0              100.000000    100  100.000000  100.000000\n",
      "18             100.000000    100   99.000000  100.000000\n",
      "0               77.214286     99   96.549451   98.807692\n",
      "4              100.000000    100  100.000000  100.000000\n",
      "56              98.000000     97  100.000000  100.000000\n",
      "1              100.000000     97  100.000000  100.000000\n",
      "0               75.000000    100   99.000000  100.000000\n",
      "18             100.000000    100   99.000000  100.000000\n",
      "28             100.000000    100  100.000000  100.000000\n",
      "0                0.000000    100   50.000000  100.000000\n",
      "9               60.000000    100   99.000000  100.000000\n",
      "0              100.000000    100  100.000000  100.000000\n",
      "...                   ...    ...         ...         ...\n",
      "65              99.000000    100  100.000000  100.000000\n",
      "0              100.000000    100  100.000000  100.000000\n",
      "21              53.000000    100   99.000000  100.000000\n",
      "0              100.000000    100   99.000000  100.000000\n",
      "0                0.000000     99   99.000000   99.000000\n",
      "8              100.000000    100  100.000000  100.000000\n",
      "9               96.000000    100  100.000000  100.000000\n",
      "6               50.000000    100  100.000000  100.000000\n",
      "0               33.000000    100  100.000000  100.000000\n",
      "11              73.500000    100  100.000000  100.000000\n",
      "10               0.000000    100  100.000000  100.000000\n",
      "10             100.000000    100  100.000000  100.000000\n",
      "0               76.000000    100  100.000000  100.000000\n",
      "0               90.000000    100  100.000000   99.000000\n",
      "35              81.000000    100  100.000000  100.000000\n",
      "0              100.000000    100  100.000000  100.000000\n",
      "0               77.214286     99   96.549451   98.807692\n",
      "5               97.000000    100  100.000000  100.000000\n",
      "8               13.000000    100  100.000000  100.000000\n",
      "7               99.000000    100  100.000000  100.000000\n",
      "14             100.000000    100  100.000000  100.000000\n",
      "0               77.214286     99   96.549451   98.807692\n",
      "3               89.000000    100  100.000000  100.000000\n",
      "5               92.000000    100  100.000000  100.000000\n",
      "0               93.000000    100  100.000000   99.000000\n",
      "9               90.000000    100  100.000000  100.000000\n",
      "0               99.000000    100  100.000000  100.000000\n",
      "0               65.000000    100  100.000000  100.000000\n",
      "0               36.000000    100  100.000000  100.000000\n",
      "0               79.000000    100  100.000000  100.000000\n",
      "\n",
      "[94 rows x 4 columns]\n",
      "X_b = \n",
      "\n",
      "[[1.00000000e+00 9.20000000e+01 1.00000000e+02 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+06]\n",
      " [1.00000000e+00 8.70000000e+01 0.00000000e+00 ... 1.00000000e+06\n",
      "  1.00000000e+06 1.00000000e+06]\n",
      " [1.00000000e+00 1.00000000e+02 1.00000000e+02 ... 9.95000000e+05\n",
      "  9.90025000e+05 9.85074875e+05]\n",
      " ...\n",
      " [1.00000000e+00 6.50000000e+01 1.00000000e+02 ... 1.00000000e+06\n",
      "  1.00000000e+06 1.00000000e+06]\n",
      " [1.00000000e+00 3.60000000e+01 1.00000000e+02 ... 1.00000000e+06\n",
      "  1.00000000e+06 1.00000000e+06]\n",
      " [1.00000000e+00 7.90000000e+01 1.00000000e+02 ... 1.00000000e+06\n",
      "  1.00000000e+06 1.00000000e+06]]\n",
      "X_normalized = \n",
      "\n",
      "[[0.54530548 0.59272335 0.         0.59272335]\n",
      " [0.5239728  0.         0.60226759 0.60226759]\n",
      " [0.50062461 0.50062461 0.50062461 0.49812148]\n",
      " [0.48089709 0.50620746 0.50620746 0.50620746]\n",
      " [0.05189152 0.57657242 0.57657242 0.57657242]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.49244366 0.50249353 0.50249353 0.50249353]\n",
      " [0.19293206 0.56744725 0.56744725 0.56461001]\n",
      " [0.16513296 0.56942401 0.56942401 0.56942401]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.0862796  0.57519731 0.57519731 0.57519731]\n",
      " [0.         0.66666667 0.33333333 0.66666667]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.48089709 0.50620746 0.50620746 0.50620746]\n",
      " [0.49359553 0.49359553 0.50886138 0.50377276]\n",
      " [0.3326771  0.5453723  0.54264543 0.5453723 ]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.50124841 0.50124841 0.49623593 0.50124841]\n",
      " [0.41362803 0.53033159 0.51720428 0.52930142]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.4961596  0.49109675 0.50628531 0.50628531]\n",
      " [0.50373519 0.48862314 0.50373519 0.50373519]\n",
      " [0.3984742  0.53129893 0.52598594 0.53129893]\n",
      " [0.50124841 0.50124841 0.49623593 0.50124841]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.         0.66666667 0.33333333 0.66666667]\n",
      " [0.32830048 0.54716746 0.54169579 0.54716746]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.37523804 0.53605434 0.53337407 0.53605434]\n",
      " [0.49623593 0.50124841 0.50124841 0.50124841]\n",
      " [0.47883677 0.50940082 0.50430681 0.50685382]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.40349543 0.53091504 0.52560589 0.52826046]\n",
      " [0.69625793 0.71779168 0.         0.        ]\n",
      " [0.48089709 0.50620746 0.50620746 0.50620746]\n",
      " [0.36544354 0.53741698 0.53741698 0.53741698]\n",
      " [0.47699146 0.50743773 0.50743773 0.50743773]\n",
      " [0.46108397 0.51231552 0.51231552 0.51231552]\n",
      " [0.48212792 0.50750307 0.50242804 0.50750307]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.14844787 0.57095336 0.57095336 0.57095336]\n",
      " [0.49368554 0.50376076 0.50376076 0.49872315]\n",
      " [0.36544354 0.53741698 0.53741698 0.53741698]\n",
      " [0.         0.58023687 0.58023687 0.57153332]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.49623593 0.50124841 0.50124841 0.50124841]\n",
      " [0.         0.57735027 0.57735027 0.57735027]\n",
      " [0.50124841 0.50124841 0.49623593 0.50124841]\n",
      " [0.4923287  0.4923287  0.50755536 0.50755536]\n",
      " [0.49623593 0.50124841 0.50124841 0.50124841]\n",
      " [0.20414712 0.56707533 0.56140458 0.56707533]\n",
      " [0.17066404 0.56888012 0.56888012 0.56888012]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.44409589 0.50679178 0.52246575 0.52246575]\n",
      " [0.45703569 0.51352325 0.51352325 0.51352325]\n",
      " [0.47305738 0.50866384 0.50866384 0.50866384]\n",
      " [0.         0.57735027 0.57735027 0.57735027]\n",
      " [0.50124841 0.50124841 0.49623593 0.50124841]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.41931393 0.52414242 0.52414242 0.52414242]\n",
      " [0.49623593 0.50124841 0.50124841 0.50124841]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.29349484 0.55376385 0.54822621 0.55376385]\n",
      " [0.50124841 0.50124841 0.49623593 0.50124841]\n",
      " [0.         0.57735027 0.57735027 0.57735027]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.4847743  0.50497323 0.50497323 0.50497323]\n",
      " [0.2773501  0.5547002  0.5547002  0.5547002 ]\n",
      " [0.18715893 0.56714829 0.56714829 0.56714829]\n",
      " [0.39063568 0.53147711 0.53147711 0.53147711]\n",
      " [0.         0.57735027 0.57735027 0.57735027]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.40180719 0.52869367 0.52869367 0.52869367]\n",
      " [0.46229285 0.51365872 0.51365872 0.50852213]\n",
      " [0.42361954 0.52298709 0.52298709 0.52298709]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.41362803 0.53033159 0.51720428 0.52930142]\n",
      " [0.48862314 0.50373519 0.50373519 0.50373519]\n",
      " [0.07484502 0.5757309  0.5757309  0.5757309 ]\n",
      " [0.49623593 0.50124841 0.50124841 0.50124841]\n",
      " [0.5        0.5        0.5        0.5       ]\n",
      " [0.41362803 0.53033159 0.51720428 0.52930142]\n",
      " [0.45703569 0.51352325 0.51352325 0.51352325]\n",
      " [0.46909478 0.50988564 0.50988564 0.50988564]\n",
      " [0.47427996 0.50997845 0.50997845 0.50487867]\n",
      " [0.46108397 0.51231552 0.51231552 0.51231552]\n",
      " [0.49623593 0.50124841 0.50124841 0.50124841]\n",
      " [0.35135135 0.54054054 0.54054054 0.54054054]\n",
      " [0.20349703 0.56526954 0.56526954 0.56526954]\n",
      " [0.41497985 0.52529094 0.52529094 0.52529094]]\n",
      "rmse =  0.8932370012631204\n",
      "rmse =  0.9509234034079381\n",
      "rmse =  0.7922496919962071\n",
      "rmse =  0.6441223618391746\n",
      "rmse =  0.5359422007578724\n",
      "rmse =  0.6014167670256413\n",
      "models[0].predict(X_normalized) =  [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "chosenModels[0] = \n",
      " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
      "          n_jobs=1, penalty='l2', random_state=None, solver='newton-cg',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.81      0.70        37\n",
      "          1       0.14      0.04      0.07        23\n",
      "          2       0.61      0.68      0.64        34\n",
      "\n",
      "avg / total       0.49      0.57      0.52        94\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.92      0.75        37\n",
      "          1       0.50      0.04      0.08        23\n",
      "          2       0.61      0.68      0.64        34\n",
      "\n",
      "avg / total       0.59      0.62      0.54        94\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.86      0.67        37\n",
      "          1       0.31      0.35      0.33        23\n",
      "          2       0.89      0.24      0.37        34\n",
      "\n",
      "avg / total       0.61      0.51      0.48        94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import datasets, linear_model, neighbors, svm, naive_bayes\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.utils import column_or_1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "def loadGrade():\n",
    "    csv_path = \"grade.csv\"\n",
    "    return pd.read_csv(csv_path, index_col = 0)\n",
    "# function to read from csv file\n",
    "def load_data(csv_path):\n",
    "\t# index = not use the first column as the index (row names)\n",
    "    return pd.read_csv(csv_path, index_col = 0)\n",
    "\n",
    "# function to return course from argument 2\n",
    "def read_in():\n",
    "\tcourse = sys.argv[1];\n",
    "\t# print('course = ',course)\n",
    "\treturn course;\n",
    "\n",
    "\n",
    "def get_rmse(model, X, y):\n",
    "# model.fit(X, y) = fit model with X and Y\n",
    "\tmodel.fit(X, y)\n",
    "# prediction = array with new prediction value from model\n",
    "\tpredictions = []\n",
    "# model.predict = Predict X using the linear model \n",
    "\tfor val in model.predict(X):\n",
    "\t\tif (val < 0.5):\n",
    "\t\t\tpredictions.append(0)\n",
    "\t\telif (val < 1.5):\n",
    "\t\t\tpredictions.append(1)\n",
    "\t\telse:\n",
    "\t\t\tpredictions.append(2)\n",
    "# compare predicts array with right value of y1 training data\n",
    "# lin_mse = error\n",
    "\tlin_mse = mean_squared_error(y, predictions) \n",
    "# \tprint( \" lin_mse \", lin_mse) \n",
    "# lin_rmse = square root( căn bậc 2 ) of lin_mse\n",
    "\tlin_rmse = np.sqrt(lin_mse)\n",
    "# \tprint( \" lin_rmse \", lin_rmse) \n",
    "\treturn lin_rmse\n",
    "\n",
    "\n",
    "    \n",
    "#Load input\n",
    "# grade from upload\n",
    "inpgrade = loadGrade()\n",
    "# names = header of all column\n",
    "names = list(inpgrade.columns.values)\n",
    "course = read_in()\n",
    "\n",
    "# print(\"course = \", course)\n",
    "\n",
    "#Rename columns\n",
    "for name in names:\n",
    "    newName = re.sub(r\"\\(.*\\)\", \"\", name).strip()\n",
    "    inpgrade.rename(columns = {name: newName}, inplace = True)\n",
    "# drop the row of NaN\n",
    "inpgrade = inpgrade.drop(inpgrade.index[0])\n",
    "#  drop the fisrt row of point \n",
    "inpgrade = inpgrade.drop(inpgrade.index[0])\n",
    "\n",
    "#  drop the column ID \n",
    "if ('ID' in inpgrade.columns.values):\n",
    "    inpgrade = inpgrade.drop('ID', axis = 1)\n",
    "#  drop the column Section\n",
    "if ('Section' in inpgrade.columns.values):\n",
    "    inpgrade = inpgrade.drop('Section', axis = 1)\n",
    "# print(\" inpgrade section = \")\n",
    "# print(inpgrade)\n",
    "\n",
    "# drop all the column of NAN\n",
    "inpgrade.dropna(axis = 1, how = 'all', inplace = True)\n",
    "# replace NaN value with 0\n",
    "inpgrade.fillna(0, inplace = True)\n",
    "inpgrade['Full name'] = inpgrade.index.values\n",
    "# choose all column with type of float64 as number\n",
    "\n",
    "# print(\"inpgrade = \", inpgrade)\n",
    "chosen = inpgrade.select_dtypes(include='float64').columns.values\n",
    "\n",
    "# print(\"inpgrade.select_dtypes(include='int') = \", inpgrade.select_dtypes(include='int'))\n",
    "\n",
    "# inpgrade1 = inpgrade.drop(['Student', 'SIS USer ID', 'SIS Login ID'])\n",
    "\n",
    "inpgrade1 = inpgrade[inpgrade.columns.difference(['Student', 'SIS User ID', 'SIS Login ID', 'Full name'])]\n",
    "\n",
    "\n",
    "# print('inpgrade1 = ', inpgrade1)\n",
    "\n",
    "# print('colum of inpgrade1 = ', len(inpgrade1.columns) ) \n",
    "\n",
    "\n",
    "if ( len(inpgrade1.columns) == 4 ):\n",
    "\tgrade = load_data(\"../../ml_scripts/data/csce156/full-grade-week1.csv\")   \n",
    "    \n",
    "elif ( len(inpgrade1.columns) == 9 ):   \n",
    "\tgrade = load_data(\"../../ml_scripts/data/csce156/full-grade-week2.csv\")\n",
    "elif ( len(inpgrade1.columns) == 18 ):\n",
    "\tgrade = load_data(\"../../ml_scripts/data/csce156/full-grade-week3.csv\")\n",
    "    \n",
    "elif ( len(inpgrade1.columns) == 22 ): \n",
    "\tgrade = load_data(\"../../ml_scripts/data/csce156/full-grade-week4.csv\")\n",
    "#fileO = open(\"ml_scripts/data/\" + course + \"/grade.json\", \"w\")\n",
    "#fileO.write(inpgrade.to_json(orient=\"records\"))\n",
    "#fileO.close() \n",
    "\n",
    "\n",
    "#Load data\n",
    "#  grade = training data\n",
    "# grade = load_data(\"../../ml_scripts/data/csce156/full-grade.csv\")\n",
    "# print('grade = ' , grade.head())\n",
    "# intersect = ['Homework 1', 'Homework 2', 'Homework 3', ..]\n",
    "# print(\"grade= \", grade)\n",
    "# print('chosen = ', chosen)\n",
    "#  name of column in chosen in grade from train data\n",
    "# intersect = [val for val in chosen if val in grade.columns.values]\n",
    "intersect = [val for val in inpgrade1]\n",
    "# print(\"intersect = \",intersect)\n",
    "# X = value from full-grade.csv train data \n",
    "X = grade[intersect]\n",
    "\n",
    "poly_degree = 3\n",
    "Poly_features = PolynomialFeatures(degree=poly_degree, interaction_only=False, include_bias=True)\n",
    "X_b = Poly_features.fit_transform(X)\n",
    "\n",
    "print('X = \\n')\n",
    "print( X)\n",
    "\n",
    "\n",
    "print('X_b = \\n')\n",
    "print( X_b)\n",
    "\n",
    "\n",
    "# Normalize the new feature vector that includes the polynomials\n",
    "normal_scaler = Normalizer().fit(X)\n",
    "X_normalized = normal_scaler.transform(X)\n",
    "\n",
    "\n",
    "print('X_normalized = \\n')\n",
    "print( X_normalized)\n",
    "\n",
    "# y = true result from train data \n",
    "y = grade[[\"Grade\"]].values.ravel()\n",
    "\n",
    "\n",
    "# predict already in full-grade.csv\n",
    "y1 = []\n",
    "for label in y:\n",
    "\tif label == \"Good\":\n",
    "\t\ty1.append(0)\n",
    "\tif label == \"OK\":\n",
    "\t\ty1.append(1)\n",
    "\tif label == \"High-risk\":\n",
    "\t\ty1.append(2)\n",
    "# print('data = ', y1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append(sklearn.linear_model.LogisticRegression(solver='newton-cg',multi_class='multinomial')) # Logistic Regression\n",
    "# print(\" models 1 = \", models)\n",
    "models.append(sklearn.naive_bayes.GaussianNB()) # Naive Bayes\n",
    "# print(\" models 2 = \", models)\n",
    "models.append(sklearn.neighbors.KNeighborsRegressor(n_neighbors=10)) # k Nearest Neighbors\n",
    "models.append(svm.SVR()) # Support Vector Machine\n",
    "#models.append(MLPRegressor(hidden_layer_sizes=(60,),activation='logistic',solver='lbfgs',learning_rate='adaptive',max_iter=1000,learning_rate_init=0.01,alpha=0.01)) # Neuron network\n",
    "models.append(DecisionTreeRegressor()) # Decision Tree\n",
    "models.append(RandomForestRegressor()) # Random Forest\n",
    "\n",
    "# print(\" models = \", models)\n",
    "\n",
    "chosenModels = [None]\n",
    "minRMSE = float(\"inf\")\n",
    "\n",
    "\n",
    "\n",
    "for model in models:\n",
    "# rmse = square root of mean square error (lin_rmse)\n",
    "\trmse = get_rmse(model, X, y1)\n",
    "# \tprint(\"model = \", model)\n",
    "\tprint(\"rmse = \", rmse)\n",
    "\tif rmse < minRMSE:\n",
    "\t\tminRMSE = rmse\n",
    "\t\tchosenModels[0] = model\n",
    "# print(\" chosenModels = \", chosenModels)\n",
    "#\n",
    "lr_pred = []\n",
    "nb_pred = []\n",
    "# print(\" models[0].predict(X) = \", models[0].predict(X))\n",
    "# print(\"X = \", X)\n",
    "# models[0].predict(X) = linear regression to predict X\n",
    "for val in models[0].predict(X):\n",
    "\tif (val < 0.5):\n",
    "# \t\tprint(\"val < 0.5  = \",val)   \n",
    "\t\tlr_pred.append(0)\n",
    "# \t\tprint(\" lr_pred < 0.5 = \", lr_pred)       \n",
    "\telif (val < 1.5):\n",
    "# \t\tprint(\"val < 1.5  = \",val)   \n",
    "\t\tlr_pred.append(1)\n",
    "# \t\tprint(\" lr_pred < 1.5 = \", lr_pred)\n",
    "\telse:\n",
    "# \t\tprint(\"val else  = \",val)   \n",
    "\t\tlr_pred.append(2)\n",
    "# \t\tprint(\" lr_pred else= \", lr_pred)\n",
    "\n",
    "# print(\"models[1].predict(X) = \",models[1].predict(X) )\n",
    "\n",
    "# models[1].predict(X) = naive Bayes to predict X \n",
    "for val in models[1].predict(X):\n",
    "\tif (val < 0.5):\n",
    "\t\tnb_pred.append(0)\n",
    "\telif (val < 1.5):\n",
    "\t\tnb_pred.append(1)\n",
    "\telse:\n",
    "\t\tnb_pred.append(2)\n",
    "        \n",
    "# print(\" lr_pred = \", lr_pred)\n",
    "# print(\" nb_pred = \", nb_pred)\n",
    "\n",
    "# lrnb_pred = combination between linear regress and naive bayes\n",
    "lrnb_pred = []\n",
    "for i in range(len(lr_pred)):\n",
    "# lrnb_pred contain the max value of lr_pred and nb_pred\n",
    "\tlrnb_pred.append(max(lr_pred[i], nb_pred[i]))\n",
    "# print(\" lrnb_pred = \", lrnb_pred)\n",
    "# print('data = ', y1)\n",
    "\n",
    "# mse = error when compare train data y1 and predict data from lrnb_pred\n",
    "mse = mean_squared_error(y1, lrnb_pred) \n",
    "#  rmse = square root of mse\n",
    "rmse = np.sqrt(mse)\n",
    "# print('rmse = ',rmse)\n",
    "# print('minRMSE = ',minRMSE)\n",
    "# compare new rmse from lrnb_pred to old minRMSE from 5 models -> take smaller value\n",
    "if (rmse <= minRMSE):\n",
    "\tchosenModels[0] = models[0]\n",
    "\tchosenModels.append(models[1])\n",
    "    \n",
    "chosenModels[0] = models[0]\n",
    "\n",
    "\n",
    "print(\"models[0].predict(X_normalized) = \",models[0].predict(X_normalized) )\n",
    "\n",
    "\n",
    "# print(\"models[0].predict(X) = \",models[0].predict(X) )\n",
    "    \n",
    "# print(\"chosenModels = \\n\" , chosenModels)\n",
    "\n",
    "\n",
    "\n",
    "#Export models to the file\n",
    "# chosenModel based on 2 evaluation round: 1st with 5 module and 2nd with lrnb_pred\n",
    "for i in range(len(chosenModels)):\n",
    "\tjoblib.dump(chosenModels[i], '../../ml_scripts/models/csce156/model' + str(i) + '.pkl')\n",
    "# \tprint(\"str(i) = \", str(i))\n",
    "\n",
    "# print(\"model[2] = \", models[2])\n",
    "\n",
    "# print(models[2].predict([[100,100,100,100,0,100,0,0,0,0,0,0,95,50,0,60,0,18]]))\n",
    "# print(models[2].predict([[100,100,100,100,99,100,100,100,100,99,100,100,97.5,90,81,85,86,19]]))\n",
    "# print(models[2].predict([[100,0,100,100,100,100,0,55,100,0,0,0,19,95,44,71,0,21]]))\n",
    "# print(models[2].predict([[100,100,100,100,99,100,100,100,100,100,100,100,87,93.5,105,98,105,25]]))\n",
    "print(\"chosenModels[0] = \\n\" , chosenModels[0])\n",
    "\n",
    "chosen_pred = []\n",
    "for val in chosenModels[0].predict(X):\n",
    "\tif (val < 0.5):\n",
    "\t\tchosen_pred.append(0)\n",
    "\telif (val < 1.5):\n",
    "\t\tchosen_pred.append(1)\n",
    "\telse:\n",
    "\t\tchosen_pred.append(2)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "res = str(len(chosenModels)) + \";\"\n",
    "#res = \"\"\n",
    "for feature in intersect:\n",
    "\tres += feature + \",\"\n",
    "# print(\"res[:-1]  = \", res[:-1])\n",
    "res = res[:-1] + \";\"\n",
    "# print(\"res  = \",res[:-1] + \";\")\n",
    "res += inpgrade.to_json(orient=\"records\")\n",
    "# print(\"inpgrade.to_json orient=records  =\", inpgrade.to_json(orient=\"records\"))\n",
    "# print(\"res = \")\n",
    "# print(res, end='', flush=True)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y1,lrnb_pred))\n",
    "\n",
    "print(classification_report(y1,lr_pred))\n",
    "\n",
    "print(classification_report(y1,nb_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lrnb pred class. report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.94        37\n",
      "          1       0.90      0.78      0.84        23\n",
      "          2       0.91      0.91      0.91        34\n",
      "\n",
      "avg / total       0.90      0.90      0.90        94\n",
      "\n",
      " lrnb pred conf. matrix = \n",
      " [[36  1  0]\n",
      " [ 2 18  3]\n",
      " [ 2  1 31]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\" lrnb pred class. report = \\n\", classification_report(y1,lrnb_pred))\n",
    "print(\" lrnb pred conf. matrix = \\n\", confusion_matrix(y1,lrnb_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb pred class. report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.86      0.81        37\n",
      "          1       0.42      0.57      0.48        23\n",
      "          2       0.76      0.47      0.58        34\n",
      "\n",
      "avg / total       0.68      0.65      0.65        94\n",
      "\n",
      " nb pred conf. matrix = \n",
      " [[32  3  2]\n",
      " [ 7 13  3]\n",
      " [ 3 15 16]]\n"
     ]
    }
   ],
   "source": [
    "print( \" nb pred class. report = \\n\", classification_report(y1,nb_pred))\n",
    "print(\" nb pred conf. matrix = \\n\", confusion_matrix(y1,nb_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lr pred class. report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.92      0.84        37\n",
      "          1       0.39      0.30      0.34        23\n",
      "          2       0.75      0.71      0.73        34\n",
      "\n",
      "avg / total       0.67      0.69      0.68        94\n",
      "\n",
      " lr pred conf. matrix = \n",
      " [[34  3  0]\n",
      " [ 8  7  8]\n",
      " [ 2  8 24]]\n"
     ]
    }
   ],
   "source": [
    "print( \" lr pred class. report = \\n\", classification_report(y1,lr_pred))\n",
    "print(\" lr pred conf. matrix = \\n\", confusion_matrix(y1,lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
