{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colum of inpgrade1 =  10\n",
      "intersect =  ['Assignment 1', 'Grade', 'Lab 1', 'Lab 2', 'Lab 3', 'answers', 'contributions', 'notes', 'questions', 'views']\n",
      "grade =               views  contributions  questions  notes  answers  Lab 1  Lab 2  \\\n",
      "days online                                                                  \n",
      "9               39              0          0      0        0    100  100.0   \n",
      "0                0              0          0      0        0    100  100.0   \n",
      "0                0              0          0      0        0    100  100.0   \n",
      "0                0              0          0      0        0    100  100.0   \n",
      "0                0              0          0      0        0    100  100.0   \n",
      "\n",
      "             Lab 3  Lab 4  Lab 5  Lab 6  Assignment 1  Assignment 2  \\\n",
      "days online                                                           \n",
      "9            100.0  100.0    100  100.0          90.0          75.0   \n",
      "0            100.0  100.0    100  100.0          99.0         107.0   \n",
      "0            100.0  100.0    100    0.0          65.0          78.0   \n",
      "0            100.0  100.0    100  100.0          36.0          98.0   \n",
      "0            100.0  100.0    100   99.0          79.0         100.0   \n",
      "\n",
      "             Assignment 3      Grade  \n",
      "days online                           \n",
      "9                    20.0  High-risk  \n",
      "0                    69.5         OK  \n",
      "0                    92.0  High-risk  \n",
      "0                   100.0  High-risk  \n",
      "0                   105.0       Good  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Good'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dacc513f327f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0mpoly_degree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0mPoly_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoly_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteraction_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m \u001b[0mX_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPoly_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X = \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \"\"\"\n\u001b[0;32m-> 1309\u001b[0;31m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m         combinations = self._combinations(n_features, self.degree,\n\u001b[1;32m   1311\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Good'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import datasets, linear_model, neighbors, svm, naive_bayes\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.utils import column_or_1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "def loadGrade():\n",
    "    csv_path = \"grade.csv\"\n",
    "    return pd.read_csv(csv_path, index_col = 0)\n",
    "# function to read from csv file\n",
    "def load_data(csv_path):\n",
    "\t# index = not use the first column as the index (row names)\n",
    "    return pd.read_csv(csv_path, index_col = 0)\n",
    "\n",
    "# function to return course from argument 2\n",
    "def read_in():\n",
    "\tcourse = sys.argv[1];\n",
    "\t# print('course = ',course)\n",
    "\treturn course;\n",
    "\n",
    "\n",
    "def get_rmse(model, X, y):\n",
    "# model.fit(X, y) = fit model with X and Y\n",
    "\tmodel.fit(X, y)\n",
    "# prediction = array with new prediction value from model\n",
    "\tpredictions = []\n",
    "# model.predict = Predict X using the linear model \n",
    "\tfor val in model.predict(X):\n",
    "\t\tif (val < 0.5):\n",
    "\t\t\tpredictions.append(0)\n",
    "\t\telif (val < 1.5):\n",
    "\t\t\tpredictions.append(1)\n",
    "\t\telse:\n",
    "\t\t\tpredictions.append(2)\n",
    "# compare predicts array with right value of y1 training data\n",
    "# lin_mse = error\n",
    "\tlin_mse = mean_squared_error(y, predictions) \n",
    "# \tprint( \" lin_mse \", lin_mse) \n",
    "# lin_rmse = square root( căn bậc 2 ) of lin_mse\n",
    "\tlin_rmse = np.sqrt(lin_mse)\n",
    "# \tprint( \" lin_rmse \", lin_rmse) \n",
    "\treturn lin_rmse\n",
    "\n",
    "\n",
    "    \n",
    "#Load input\n",
    "# grade from upload\n",
    "inpgrade = loadGrade()\n",
    "# names = header of all column\n",
    "names = list(inpgrade.columns.values)\n",
    "course = read_in()\n",
    "\n",
    "# print(\"course = \", course)\n",
    "\n",
    "#Rename columns\n",
    "for name in names:\n",
    "    newName = re.sub(r\"\\(.*\\)\", \"\", name).strip()\n",
    "    inpgrade.rename(columns = {name: newName}, inplace = True)\n",
    "# drop the row of NaN\n",
    "inpgrade = inpgrade.drop(inpgrade.index[0])\n",
    "#  drop the fisrt row of point \n",
    "inpgrade = inpgrade.drop(inpgrade.index[0])\n",
    "\n",
    "#  drop the column ID \n",
    "if ('ID' in inpgrade.columns.values):\n",
    "    inpgrade = inpgrade.drop('ID', axis = 1)\n",
    "#  drop the column Section\n",
    "if ('Section' in inpgrade.columns.values):\n",
    "    inpgrade = inpgrade.drop('Section', axis = 1)\n",
    "# print(\" inpgrade section = \")\n",
    "# print(inpgrade)\n",
    "\n",
    "# drop all the column of NAN\n",
    "inpgrade.dropna(axis = 1, how = 'all', inplace = True)\n",
    "# replace NaN value with 0\n",
    "inpgrade.fillna(0, inplace = True)\n",
    "inpgrade['Full name'] = inpgrade.index.values\n",
    "# choose all column with type of float64 as number\n",
    "\n",
    "# print(\"inpgrade = \", inpgrade)\n",
    "chosen = inpgrade.select_dtypes(include='float64').columns.values\n",
    "\n",
    "# print(\"inpgrade.select_dtypes(include='int') = \", inpgrade.select_dtypes(include='int'))\n",
    "\n",
    "# inpgrade1 = inpgrade.drop(['Student', 'SIS USer ID', 'SIS Login ID'])\n",
    "\n",
    "inpgrade1 = inpgrade[inpgrade.columns.difference(['Student', 'SIS User ID', 'SIS Login ID', 'Full name'])]\n",
    "\n",
    "\n",
    "# print('inpgrade1 = ', inpgrade1)\n",
    "\n",
    "print('colum of inpgrade1 = ', len(inpgrade1.columns) ) \n",
    "\n",
    "\n",
    "if ( len(inpgrade1.columns) == 4 ):\n",
    "\tprint(\"hung\")    \n",
    "# \tgrade = load_data(\"../../ml_scripts/data/csce156/MasterTrainingData1.csv\") \n",
    "\tgrade = load_data(\"../../ml_scripts/data/csce156/full-grade-week1.csv\")   \n",
    "    \n",
    "elif ( len(inpgrade1.columns) == 9 ):   \n",
    "\tgrade = load_data(\"../../ml_scripts/data/csce156/full-grade-week2.csv\")\n",
    "elif ( len(inpgrade1.columns) == 18 ):\n",
    "\tgrade = load_data(\"../../ml_scripts/data/csce156/full-grade-week3.csv\")\n",
    "    \n",
    "elif ( len(inpgrade1.columns) == 22 ): \n",
    "\tgrade = load_data(\"../../ml_scripts/data/csce156/full-grade-week4.csv\")\n",
    "#fileO = open(\"ml_scripts/data/\" + course + \"/grade.json\", \"w\")\n",
    "#fileO.write(inpgrade.to_json(orient=\"records\"))\n",
    "#fileO.close() \n",
    "\n",
    "\n",
    "#Load data\n",
    "#  grade = training data\n",
    "# grade = load_data(\"../../ml_scripts/data/csce156/full-grade.csv\")\n",
    "# print('grade = ' , grade.head())\n",
    "# intersect = ['Homework 1', 'Homework 2', 'Homework 3', ..]\n",
    "# print(\"grade= \", grade)\n",
    "# print('chosen = ', chosen)\n",
    "#  name of column in chosen in grade from train data\n",
    "# intersect = [val for val in chosen if val in grade.columns.values]\n",
    "intersect = [val for val in inpgrade1]\n",
    "print(\"intersect = \",intersect)\n",
    "print(\"grade = \", grade.tail())\n",
    "# X = value from full-grade.csv train data \n",
    "X = grade[intersect]\n",
    "\n",
    "poly_degree = 2\n",
    "Poly_features = PolynomialFeatures(degree=poly_degree, interaction_only=False, include_bias=True)\n",
    "X_b = Poly_features.fit_transform(X)\n",
    "\n",
    "print('X = \\n')\n",
    "print( X)\n",
    "\n",
    "\n",
    "# print('X_b = \\n')\n",
    "# print( X_b)\n",
    "\n",
    "\n",
    "# Normalize the new feature vector that includes the polynomials\n",
    "normal_scaler = Normalizer().fit(X_b)\n",
    "X_normalized = normal_scaler.transform(X_b)\n",
    "\n",
    "\n",
    "# print('X_normalized = \\n')\n",
    "# print( X_normalized)\n",
    "\n",
    "# y = true result from train data \n",
    "y = grade[[\"Grade\"]].values.ravel()\n",
    "\n",
    "\n",
    "# predict already in full-grade.csv\n",
    "y1 = []\n",
    "for label in y:\n",
    "\tif label == \"Good\":\n",
    "\t\ty1.append(0)\n",
    "\tif label == \"OK\":\n",
    "\t\ty1.append(1)\n",
    "\tif label == \"High-risk\":\n",
    "\t\ty1.append(2)\n",
    "# print('data = ', y1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append(LogisticRegression(solver='newton-cg',multi_class='multinomial')) # Logistic Regression\n",
    "# print(\" models 1 = \", models)\n",
    "models.append(sklearn.naive_bayes.GaussianNB()) # Naive Bayes\n",
    "# print(\" models 2 = \", models)\n",
    "models.append(sklearn.neighbors.KNeighborsRegressor(n_neighbors=10)) # k Nearest Neighbors\n",
    "models.append(svm.SVR()) # Support Vector Machine\n",
    "#models.append(MLPRegressor(hidden_layer_sizes=(60,),activation='logistic',solver='lbfgs',learning_rate='adaptive',max_iter=1000,learning_rate_init=0.01,alpha=0.01)) # Neuron network\n",
    "models.append(DecisionTreeRegressor()) # Decision Tree\n",
    "models.append(RandomForestRegressor()) # Random Forest\n",
    "\n",
    "# print(\" models = \", models)\n",
    "                                                      \n",
    "clf = LogisticRegression(random_state=0, class_weight='balanced')\n",
    "\n",
    "print(\"clf =\", clf)\n",
    "                                                      \n",
    "                                                      \n",
    "chosenModels = [None]\n",
    "minRMSE = float(\"inf\")\n",
    "\n",
    "\n",
    "\n",
    "for model in models:\n",
    "# rmse = square root of mean square error (lin_rmse)\n",
    "\trmse = get_rmse(model, X, y1)\n",
    "# \tprint(\"model = \", model)\n",
    "\tprint(\"rmse = \", rmse)\n",
    "\tif rmse < minRMSE:\n",
    "\t\tminRMSE = rmse\n",
    "\t\tchosenModels[0] = model\n",
    "# print(\" chosenModels = \", chosenModels)\n",
    "#\n",
    "lr_pred = []\n",
    "nb_pred = []\n",
    "# print(\" models[0].predict(X) = \", models[0].predict(X))\n",
    "# print(\"X = \", X)\n",
    "# models[0].predict(X) = linear regression to predict X\n",
    "for val in models[0].predict(X):\n",
    "\tif (val < 0.5):\n",
    "# \t\tprint(\"val < 0.5  = \",val)   \n",
    "\t\tlr_pred.append(0)\n",
    "# \t\tprint(\" lr_pred < 0.5 = \", lr_pred)       \n",
    "\telif (val < 1.5):\n",
    "# \t\tprint(\"val < 1.5  = \",val)   \n",
    "\t\tlr_pred.append(1)\n",
    "# \t\tprint(\" lr_pred < 1.5 = \", lr_pred)\n",
    "\telse:\n",
    "# \t\tprint(\"val else  = \",val)   \n",
    "\t\tlr_pred.append(2)\n",
    "# \t\tprint(\" lr_pred else= \", lr_pred)\n",
    "\n",
    "# print(\"models[1].predict(X) = \",models[1].predict(X) )\n",
    "\n",
    "# models[1].predict(X) = naive Bayes to predict X \n",
    "for val in models[1].predict(X):\n",
    "\tif (val < 0.5):\n",
    "\t\tnb_pred.append(0)\n",
    "\telif (val < 1.5):\n",
    "\t\tnb_pred.append(1)\n",
    "\telse:\n",
    "\t\tnb_pred.append(2)\n",
    "        \n",
    "# print(\" lr_pred = \", lr_pred)\n",
    "# print(\" nb_pred = \", nb_pred)\n",
    "\n",
    "# lrnb_pred = combination between linear regress and naive bayes\n",
    "lrnb_pred = []\n",
    "for i in range(len(lr_pred)):\n",
    "# lrnb_pred contain the max value of lr_pred and nb_pred\n",
    "\tlrnb_pred.append(max(lr_pred[i], nb_pred[i]))\n",
    "# print(\" lrnb_pred = \", lrnb_pred)\n",
    "# print('data = ', y1)\n",
    "\n",
    "# mse = error when compare train data y1 and predict data from lrnb_pred\n",
    "mse = mean_squared_error(y1, lrnb_pred) \n",
    "#  rmse = square root of mse\n",
    "rmse = np.sqrt(mse)\n",
    "# print('rmse = ',rmse)\n",
    "# print('minRMSE = ',minRMSE)\n",
    "# compare new rmse from lrnb_pred to old minRMSE from 5 models -> take smaller value\n",
    "if (rmse <= minRMSE):\n",
    "\tchosenModels[0] = models[0]\n",
    "\tchosenModels.append(models[1])\n",
    "    \n",
    "# chosenModels[0] = models[0]\n",
    "\n",
    "\n",
    "# print(\"models[0].predict(X_normalized) = \",models[0].predict(X_normalized) )\n",
    "\n",
    "\n",
    "# print(\"models[0].predict(X) = \",models[0].predict(X) )\n",
    "    \n",
    "print(\"chosenModels = \\n\" , chosenModels)\n",
    "print(\"len(chosenModels)= \\n\" , len(chosenModels))\n",
    "\n",
    "\n",
    "#Export models to the file\n",
    "# chosenModel based on 2 evaluation round: 1st with 5 module and 2nd with lrnb_pred\n",
    "for i in range(len(chosenModels)):\n",
    "\tjoblib.dump(chosenModels[i], '../../ml_scripts/models/csce156/model' + str(i) + '.pkl')\n",
    "# \tprint(\"str(i) = \", str(i))\n",
    "\n",
    "# print(\"model[2] = \", models[2])\n",
    "\n",
    "# print(models[2].predict([[100,100,100,100,0,100,0,0,0,0,0,0,95,50,0,60,0,18]]))\n",
    "# print(models[2].predict([[100,100,100,100,99,100,100,100,100,99,100,100,97.5,90,81,85,86,19]]))\n",
    "# print(models[2].predict([[100,0,100,100,100,100,0,55,100,0,0,0,19,95,44,71,0,21]]))\n",
    "# print(models[2].predict([[100,100,100,100,99,100,100,100,100,100,100,100,87,93.5,105,98,105,25]]))\n",
    "print(\"chosenModels[0] = \\n\" , chosenModels[0])\n",
    "\n",
    "chosen_pred = []\n",
    "for val in chosenModels[0].predict(X):\n",
    "\tif (val < 0.5):\n",
    "\t\tchosen_pred.append(0)\n",
    "\telif (val < 1.5):\n",
    "\t\tchosen_pred.append(1)\n",
    "\telse:\n",
    "\t\tchosen_pred.append(2)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "res = str(len(chosenModels)) + \";\"\n",
    "#res = \"\"\n",
    "for feature in intersect:\n",
    "\tres += feature + \",\"\n",
    "# print(\"res[:-1]  = \", res[:-1])\n",
    "res = res[:-1] + \";\"\n",
    "# print(\"res  = \",res[:-1] + \";\")\n",
    "res += inpgrade.to_json(orient=\"records\")\n",
    "# print(\"inpgrade.to_json orient=records  =\", inpgrade.to_json(orient=\"records\"))\n",
    "# print(\"res = \")\n",
    "# print(res, end='', flush=True)\n",
    "\n",
    "\n",
    "\n",
    "# print(classification_report(y1,lrnb_pred))\n",
    "\n",
    "# print(classification_report(y1,lr_pred))\n",
    "\n",
    "# print(classification_report(y1,nb_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# print(\" lrnb pred class. report = \\n\", classification_report(y1,lrnb_pred))\n",
    "# print(\" lrnb pred conf. matrix = \\n\", confusion_matrix(y1,lrnb_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb pred class. report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.86      0.81        37\n",
      "          1       0.42      0.57      0.48        23\n",
      "          2       0.76      0.47      0.58        34\n",
      "\n",
      "avg / total       0.68      0.65      0.65        94\n",
      "\n",
      " nb pred conf. matrix = \n",
      " [[32  3  2]\n",
      " [ 7 13  3]\n",
      " [ 3 15 16]]\n"
     ]
    }
   ],
   "source": [
    "# print( \" nb pred class. report = \\n\", classification_report(y1,nb_pred))\n",
    "# print(\" nb pred conf. matrix = \\n\", confusion_matrix(y1,nb_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lr pred class. report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.92      0.84        37\n",
      "          1       0.39      0.30      0.34        23\n",
      "          2       0.75      0.71      0.73        34\n",
      "\n",
      "avg / total       0.67      0.69      0.68        94\n",
      "\n",
      " lr pred conf. matrix = \n",
      " [[34  3  0]\n",
      " [ 8  7  8]\n",
      " [ 2  8 24]]\n"
     ]
    }
   ],
   "source": [
    "# print( \" lr pred class. report = \\n\", classification_report(y1,lr_pred))\n",
    "# print(\" lr pred conf. matrix = \\n\", confusion_matrix(y1,lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
