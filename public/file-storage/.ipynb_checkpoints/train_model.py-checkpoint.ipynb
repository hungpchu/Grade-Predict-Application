{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersect =  ['Lab 1', 'Lab 2', 'Lab 3', 'Lab 4', 'Lab 5', 'Lab 6', 'Lab 7', 'Lab 8', 'Lab 9', 'Lab 10', 'Lab 11', 'Lab 12', 'Lab 13', 'Lab 14', 'Lab 15', 'Assignment 1', 'Assignment 2', 'Assignment 3', 'Assignment 4', 'Assignment 5', 'Assignment 6', 'Design Document', 'Late Pass', 'Midterm', 'Final', 'Weighted Total']\n",
      "X =               Lab 1  Lab 2  Lab 3  Lab 4  Lab 5  Lab 6  Lab 7  Lab 8  Lab 9  \\\n",
      "days online                                                                  \n",
      "0              100    0.0  100.0  100.0    100  100.0      0      0      0   \n",
      "1                0  100.0  100.0  100.0     99  100.0      0    100    100   \n",
      "7              100  100.0   99.5  100.0    100  100.0    100    100    100   \n",
      "0              100  100.0  100.0  100.0    100  100.0    100    100    100   \n",
      "19             100  100.0  100.0  100.0    100  100.0    100    100    100   \n",
      "\n",
      "             Lab 10       ...        Assignment 2  Assignment 3  Assignment 4  \\\n",
      "days online               ...                                                   \n",
      "0                 0       ...                85.0          70.0           0.0   \n",
      "1               100       ...               112.0         100.0         102.5   \n",
      "7               100       ...               100.0         102.0         100.0   \n",
      "0               100       ...               100.0         105.0         105.0   \n",
      "19                0       ...               105.0          70.0          95.0   \n",
      "\n",
      "             Assignment 5  Assignment 6  Design Document  Late Pass  Midterm  \\\n",
      "days online                                                                    \n",
      "0                    75.0           0.0              0.0          1       35   \n",
      "1                    47.0          91.0             92.5          2       48   \n",
      "7                    87.0          93.0             95.0          1       48   \n",
      "0                   100.0          71.0            100.0          1       50   \n",
      "19                   75.0           0.0            105.0          1        0   \n",
      "\n",
      "             Final  Weighted Total  \n",
      "days online                         \n",
      "0                0       43.900000  \n",
      "1               26       89.694286  \n",
      "7               26       94.887857  \n",
      "0               25       94.914286  \n",
      "19              17       63.478571  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "data =  [2, 1, 0, 0, 2, 1, 0, 1, 1, 2, 0, 0, 2, 2, 0, 0, 1, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2, 2, 1, 2, 1, 2, 0, 2, 1, 2, 2, 0, 0, 2, 2, 1, 0, 0, 1, 2, 0, 2, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 2, 2, 0, 0, 1, 0, 1, 1, 1, 1, 2, 1, 0, 2, 0, 2, 0, 0, 1, 0, 2, 2, 2, 1, 2, 2, 0]\n",
      "chosenModels[0] =  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
      "          n_jobs=1, penalty='l2', random_state=None, solver='newton-cg',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import datasets, linear_model, neighbors, svm, naive_bayes\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.utils import column_or_1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "def loadGrade():\n",
    "    csv_path = \"grade.csv\"\n",
    "    return pd.read_csv(csv_path, index_col = 0)\n",
    "# function to read from csv file\n",
    "def load_data(csv_path):\n",
    "\t# index = not use the first column as the index (row names)\n",
    "    return pd.read_csv(csv_path, index_col = 0)\n",
    "\n",
    "# function to return course from argument 2\n",
    "def read_in():\n",
    "\tcourse = sys.argv[1];\n",
    "\t# print('course = ',course)\n",
    "\treturn course;\n",
    "\n",
    "def get_rmse(model, X, y):\n",
    "\tmodel.fit(X, y)\n",
    "\tpredictions = []\n",
    "\tfor val in model.predict(X):\n",
    "\t\tif (val < 0.5):\n",
    "\t\t\tpredictions.append(0)\n",
    "\t\telif (val < 1.5):\n",
    "\t\t\tpredictions.append(1)\n",
    "\t\telse:\n",
    "\t\t\tpredictions.append(2)\n",
    "\tlin_mse = mean_squared_error(y, predictions) \n",
    "\tlin_rmse = np.sqrt(lin_mse)\n",
    "\treturn lin_rmse\n",
    "\t\n",
    "#Load input\n",
    "\n",
    "# inpgrade = table of input data\n",
    "inpgrade = loadGrade()\n",
    "# names = header of all column\n",
    "names = list(inpgrade.columns.values)\n",
    "course = read_in()\n",
    "\n",
    "#Rename columns\n",
    "for name in names:\n",
    "    newName = re.sub(r\"\\(.*\\)\", \"\", name).strip()\n",
    "    inpgrade.rename(columns = {name: newName}, inplace = True)\n",
    "# drop the row of NaN\n",
    "inpgrade = inpgrade.drop(inpgrade.index[0])\n",
    "#  drop the fisrt row of point \n",
    "inpgrade = inpgrade.drop(inpgrade.index[0])\n",
    "\n",
    "#  drop the column ID \n",
    "if ('ID' in inpgrade.columns.values):\n",
    "    inpgrade = inpgrade.drop('ID', axis = 1)\n",
    "#  drop the column Section\n",
    "if ('Section' in inpgrade.columns.values):\n",
    "    inpgrade = inpgrade.drop('Section', axis = 1)\n",
    "# print(\" inpgrade section = \")\n",
    "# print(inpgrade)\n",
    "\n",
    "# drop all the column of NAN\n",
    "inpgrade.dropna(axis = 1, how = 'all', inplace = True)\n",
    "# replace NaN value with 0\n",
    "inpgrade.fillna(0, inplace = True)\n",
    "inpgrade['Full name'] = inpgrade.index.values\n",
    "# choose all column with type of float64 as number\n",
    "chosen = inpgrade.select_dtypes(include='float64').columns.values\n",
    "#fileO = open(\"ml_scripts/data/\" + course + \"/grade.json\", \"w\")\n",
    "#fileO.write(inpgrade.to_json(orient=\"records\"))\n",
    "#fileO.close() \n",
    "\n",
    "#Load data\n",
    "#  grade = data for training\n",
    "grade = load_data(\"../../ml_scripts/data/csce156/full-grade.csv\")\n",
    "# print('grade = ' , grade.head())\n",
    "# intersect = ['Homework 1', 'Homework 2', 'Homework 3', ..]\n",
    "# print('grade.columns = ', grade.columns)\n",
    "# print('chosen = ', chosen)\n",
    "intersect = [val for val in chosen if val in grade.columns.values]\n",
    "print(\"intersect = \",intersect)\n",
    "# X = all value of ['Homework 1', 'Homework 2', 'Homework 3', ..]\n",
    "X = grade[intersect]\n",
    "print('X = ', X.head())\n",
    "# y contain all high-risk thing \n",
    "y = grade[[\"Grade\"]].values.ravel()\n",
    "y1 = []\n",
    "for label in y:\n",
    "\tif label == \"Good\":\n",
    "\t\ty1.append(0)\n",
    "\tif label == \"OK\":\n",
    "\t\ty1.append(1)\n",
    "\tif label == \"High-risk\":\n",
    "\t\ty1.append(2)\n",
    "print('data = ', y1)\n",
    "\n",
    "models = []\n",
    "models.append(sklearn.linear_model.LogisticRegression(solver='newton-cg',multi_class='multinomial')) # Logistic Regression\n",
    "# print(\" models 1 = \", models)\n",
    "models.append(sklearn.naive_bayes.GaussianNB()) # Naive Bayes\n",
    "# print(\" models 2 = \", models)\n",
    "models.append(sklearn.neighbors.KNeighborsRegressor(n_neighbors=10)) # k Nearest Neighbors\n",
    "models.append(svm.SVR()) # Support Vector Machine\n",
    "#models.append(MLPRegressor(hidden_layer_sizes=(60,),activation='logistic',solver='lbfgs',learning_rate='adaptive',max_iter=1000,learning_rate_init=0.01,alpha=0.01)) # Neuron network\n",
    "models.append(DecisionTreeRegressor()) # Decision Tree\n",
    "models.append(RandomForestRegressor()) # Random Forest\n",
    "\n",
    "# print(\" models = \", models)\n",
    "\n",
    "chosenModels = [None]\n",
    "minRMSE = float(\"inf\")\n",
    "\n",
    "\n",
    "for model in models:\n",
    "\trmse = get_rmse(model, X, y1)\n",
    "# \tprint(\"model = \", model)\n",
    "# \tprint(\"rmse = \", rmse)\n",
    "\tif rmse < minRMSE:\n",
    "\t\tminRMSE = rmse\n",
    "\t\tchosenModels[0] = model\n",
    "# print(\" chosenModels = \", chosenModels)\n",
    "#\n",
    "lr_pred = []\n",
    "nb_pred = []\n",
    "# print(\" models[0].predict(X) = \", models[0].predict(X))\n",
    "# print(\"X = \", X)\n",
    "for val in models[0].predict(X):\n",
    "\tif (val < 0.5):\n",
    "# \t\tprint(\"val < 0.5  = \",val)   \n",
    "\t\tlr_pred.append(0)\n",
    "# \t\tprint(\" lr_pred < 0.5 = \", lr_pred)       \n",
    "\telif (val < 1.5):\n",
    "# \t\tprint(\"val < 1.5  = \",val)   \n",
    "\t\tlr_pred.append(1)\n",
    "# \t\tprint(\" lr_pred < 1.5 = \", lr_pred)\n",
    "\telse:\n",
    "# \t\tprint(\"val else  = \",val)   \n",
    "\t\tlr_pred.append(2)\n",
    "# \t\tprint(\" lr_pred else= \", lr_pred)\n",
    "\n",
    "# print(\"models[1].predict(X) = \",models[1].predict(X) )\n",
    "        \n",
    "for val in models[1].predict(X):\n",
    "\tif (val < 0.5):\n",
    "\t\tnb_pred.append(0)\n",
    "\telif (val < 1.5):\n",
    "\t\tnb_pred.append(1)\n",
    "\telse:\n",
    "\t\tnb_pred.append(2)\n",
    "        \n",
    "lrnb_pred = []\n",
    "for i in range(len(lr_pred)):\n",
    "\tlrnb_pred.append(max(lr_pred[i], nb_pred[i]))\n",
    "# print(\" lrnb_pred = \", lrnb_pred)\n",
    "# print('data = ', y1)\n",
    "\n",
    "mse = mean_squared_error(y1, lrnb_pred) \n",
    "rmse = np.sqrt(mse)\n",
    "# print('rmse = ',rmse)\n",
    "# print('minRMSE = ',minRMSE)\n",
    "if (rmse <= minRMSE):\n",
    "\tchosenModels[0] = models[0]\n",
    "\tchosenModels.append(models[1])\n",
    "\n",
    "#Export models to the file\n",
    "for i in range(len(chosenModels)):\n",
    "\tjoblib.dump(chosenModels[i], '../../ml_scripts/models/csce156/model' + str(i) + '.pkl')\n",
    "# \tprint(\"str(i) = \", str(i))\n",
    "\n",
    "# print(chosenModels[0].predict([[100,100,100,100,10,10,10,10,30,10]]))\n",
    "# print(chosenModels[0].predict([[0,0,0,0,0,0,0,0,0,0]]))\n",
    "# print(chosenModels[0].predict([[100,90,90,70,10,10,10,10,20,10]]))\n",
    "\n",
    "print(\"chosenModels[0] = \" , chosenModels[0])\n",
    "res = str(len(chosenModels)) + \";\"\n",
    "#res = \"\"\n",
    "for feature in intersect:\n",
    "\tres += feature + \",\"\n",
    "# print(\"res[:-1]  = \", res[:-1])\n",
    "res = res[:-1] + \";\"\n",
    "# print(\"res  = \",res[:-1] + \";\")\n",
    "res += inpgrade.to_json(orient=\"records\")\n",
    "# print(\"inpgrade.to_json orient=records  =\", inpgrade.to_json(orient=\"records\"))\n",
    "# print(\"res = \")\n",
    "# print(res, end='', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
